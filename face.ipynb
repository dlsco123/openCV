{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "if not os.path.exists('face'):\n",
    "    os.makedirs('face')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') #정면인식하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[454, 103,  55,  55],\n",
       "       [573, 122,  59,  59],\n",
       "       [366, 123,  53,  53],\n",
       "       [277, 233,  49,  49],\n",
       "       [129, 158,  55,  55],\n",
       "       [272, 180,  51,  51]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('open_cv_1.jpg')  # cv2는 기본으로 array로 들어옴\n",
    "\n",
    "faces = face_cascade.detectMultiScale(img, 1.024, 5) # scale factor = 1.*\n",
    "faces   # 얼굴인식 위치 값 (4명만 인식함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([454, 103,  55,  55])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the font, size, color, thickness as you like\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 1\n",
    "color = (255, 255, 255)  # white color\n",
    "thickness = 2\n",
    "\n",
    "cnt = 0\n",
    "for x, y, w, h in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Position where the count will be written\n",
    "    org = (x, y-10)  # just above the rectangle\n",
    "\n",
    "    # Put the count on the image\n",
    "    cv2.putText(img, str(cnt), org, font, fontScale, color, thickness)\n",
    "\n",
    "    cnt += 1\n",
    "\n",
    "cv2.imshow(\"test\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기존에 그려진 사각박스가 있어서 이미지를 다시 부름, \n",
    "## 얼굴인식하는 모델에 넣기위해서 박스값을 변경함\n",
    "## cv2.putText 을 이용하여서 박스위에 'face' 라는 글자를 입력함   / 구글검색 'cv2.putText'\n",
    "## 'face' 가 아닌 한글로 출력하고자 한다면 구글검색 '오픈cv 한글'\n",
    "\n",
    "img = cv2.imread('open_cv_1.jpg')  # cv2는 기본으로 array로 들어옴\n",
    "\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)  \n",
    "    cv2.putText(img, \"face\" , (x,y-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "    \n",
    "cv2.imshow(\"test\", img)   #  cv2.imshow('캡션명 사용자 마음임',출력할 이미지 변수명)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n"
     ]
    }
   ],
   "source": [
    "### 얼굴이미지만 별도로 저장하고자 한다면\n",
    "img = cv2.imread('open_cv_1.jpg')  # cv2는 기본으로 array로 들어옴\n",
    "cnt=0\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    # cv2.rectangle(img, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)  \n",
    "    # cv2.putText(img, \"face\" , (x,y-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    cnt=cnt+1\n",
    "    사각영역array = img[y-20:y + h+20, x-20:x + w+20]   # array로 되어 있는 자료만 별도로 저장하기 위해서 행렬 자료로 작업함\n",
    "    fileName='./face/' + str(cnt) + 'face.jpg'  #cnt는 순서번호를 붙이기 위해서임\n",
    "    cv2.imwrite(fileName,사각영역array)\n",
    "    \n",
    "    \n",
    "print('현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성별인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여자0, 남자 1로 성별 구별하는 모델 (티처블머신러닝에서 작업함)\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('keras_model.h5')  \n",
    "\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# create directories for saving cropped images\n",
    "if not os.path.exists('male'):\n",
    "    os.mkdir('male')\n",
    "if not os.path.exists('female'):\n",
    "    os.mkdir('female')\n",
    "\n",
    "class_name=['Female','Male']     \n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 이미지 불러오기\n",
    "img = cv2.imread('open_cv_1.jpg')\n",
    "\n",
    "# 얼굴 찾기\n",
    "faces = face_cascade.detectMultiScale(img, 1.05, 5)\n",
    "\n",
    "cnt=0\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "    roi = img[y-20:y + h+20, x-20:x + w+20]    \n",
    "    # resize the roi to the size model expects\n",
    "    resized_roi = cv2.resize(roi, (224, 224))\n",
    "    # normalize the roi as done during training of the model\n",
    "    img_array = (resized_roi/127.0) - 1\n",
    "    # reshape the array to the model expected shape\n",
    "    img_array = img_array.reshape(1, 224, 224, 3)\n",
    "    # use the model to predict the gender\n",
    "    prediction = model.predict(img_array)\n",
    "    # get the gender with highest predicted probability\n",
    "    gender_index = np.argmax(prediction)\n",
    "    # get the gender name\n",
    "    gender = class_name[gender_index]\n",
    "    # put the gender text above the rectangle\n",
    "    cnt += 1\n",
    "    cv2.putText(img, f\"{cnt}{gender}\", (x-10,y-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "    # save the cropped face image in the corresponding gender directory\n",
    "    cv2.imwrite(f'./{gender.lower()}/face{cnt}{gender.lower()}.png', roi)    \n",
    "\n",
    "cv2.imshow(\"test\", img)   #  cv2.imshow('캡션명 사용자 마음임',출력할 이미지 변수명)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.5.0-cp39-cp39-win_amd64.whl (10.5 MB)\n",
      "     --------------------------------------- 10.5/10.5 MB 38.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 비디오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# 비디오 실행\n",
    "webcam = cv2.VideoCapture(0)\n",
    "webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "while webcam.isOpened():\n",
    "    status, frame = webcam.read()\n",
    "\n",
    "    if status:\n",
    "        cv2.imshow(\"test\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 frame단위로 저장\n",
    "# Set up webcam\n",
    "webcam = cv2.VideoCapture(0)                # 비디오캠 활성화\n",
    "webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)   # 비디오 사이즈설정\n",
    "webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# Check if webcam is opened correctly\n",
    "try:\n",
    "    if not webcam.isOpened():                # 캠을 닫기 전까지\n",
    "        raise ValueError(\"Could not open webcam\")\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    exit()\n",
    "\n",
    "# Initialize frame counter\n",
    "frame_counter = 0\n",
    "while webcam.isOpened():\n",
    "    # Read frame from webcam\n",
    "    status, frame = webcam.read()    \n",
    "    # If frame was successfully read\n",
    "    if status:\n",
    "        # Display frame\n",
    "        cv2.imshow(\"test\", frame)       # Status True, Frame은 사진1장씩 들어옴\n",
    "        # Save every 100th frame to disk\n",
    "        if frame_counter % 100 == 0:\n",
    "            cv2.imwrite(f\"frame_{frame_counter}.png\", frame)    # 비디오 화면으로 출력\n",
    "        frame_counter += 1\n",
    "    # Exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):       #waitKey(1)은  1/1000 초 단위로 프레임보이기임.\n",
    "        break                                   #waitKey(3000) 으로 하면 3초단위로 비디오가 출력됨\n",
    "\n",
    "# Release webcam and close windows\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A키로 저장\n",
    "webcam = cv2.VideoCapture(0)\n",
    "webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "cnt=0\n",
    "if not webcam.isOpened():\n",
    "        print(\"Could not open webcam\")\n",
    "        exit()\n",
    "while webcam.isOpened():\n",
    "    status, frame = webcam.read()\n",
    "    if status:\n",
    "        cv2.imshow(\"test\", frame)\n",
    "\n",
    "        if cv2.waitKey(1)==ord('a'):\n",
    "            fileName='frame' + str(cnt) + '.jpg'\n",
    "            cv2.imwrite('d:/output/'+fileName, frame)\n",
    "            print('a키가 눌려서 저장되었습니다.')\n",
    "            cnt+=1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# load gender prediction model\n",
    "model = load_model('keras_model.h5')\n",
    "# define class names\n",
    "class_name = ['Female', 'Male']\n",
    "# load the opencv face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# start webcam\n",
    "webcam = cv2.VideoCapture(0)\n",
    "webcam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "webcam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "# check if webcam is opened correctly\n",
    "if not webcam.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "# create directories if not exists\n",
    "if not os.path.exists('female'):\n",
    "    os.makedirs('female')\n",
    "if not os.path.exists('male'):\n",
    "    os.makedirs('male')\n",
    "\n",
    "# initialize face counter\n",
    "face_counter = {'female': 0, 'male': 0}\n",
    "\n",
    "while webcam.isOpened():\n",
    "    # read frame from webcam\n",
    "    status, frame = webcam.read()\n",
    "    \n",
    "    if status:\n",
    "        # convert color style from BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)        \n",
    "        # detect faces\n",
    "        faces = face_cascade.detectMultiScale(frame_rgb, 1.1, 5) \n",
    "        number_of_people = len(faces)       \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)            \n",
    "            # crop the face\n",
    "            face_roi = frame_rgb[y:y+h, x:x+w]\n",
    "            # preprocessing for gender detection model\n",
    "            face_roi_resized = cv2.resize(face_roi, (224, 224))\n",
    "            face_roi_normalized = (face_roi_resized / 127.0) - 1\n",
    "            face_roi_expanded = np.expand_dims(face_roi_normalized, axis=0)            \n",
    "            # predict the gender\n",
    "            prediction = model.predict(face_roi_expanded)\n",
    "            gender = class_name[np.argmax(prediction)]            \n",
    "            # put the gender text above the rectangle\n",
    "            cv2.putText(frame, gender, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,0,0), 2)\n",
    "            \n",
    "            # if 'A' key is pressed, save the face image to corresponding gender folder\n",
    "            if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "                face_counter[gender.lower()] += 1\n",
    "                # Resize the face_roi before saving\n",
    "                face_roi_resized_for_saving = cv2.resize(face_roi, (400, 400))\n",
    "                cv2.imwrite(f'./{gender.lower()}/face_{face_counter[gender.lower()]}.png', cv2.cvtColor(face_roi, cv2.COLOR_RGB2BGR))    \n",
    "            \n",
    "        # Display the number of people at the top of the frame\n",
    "        cv2.putText(frame, f\"Number of people: {number_of_people}\", (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,0,0), 2)\n",
    "\n",
    "        # display output\n",
    "        cv2.imshow(\"test\", frame)\n",
    "    # exit loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release resources\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
